{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra functions for lr_find\n",
    "class ParameterModule(nn.Module):\n",
    "    \"Register a lone parameter 'p' in a module\"\n",
    "    def __init__(self, p:nn.Parameter):\n",
    "        super().__init__()\n",
    "        self.val = p\n",
    "    def forward(self, x): return x\n",
    "\n",
    "def children_and_parameters(m:nn.Module):\n",
    "    \"Return the children of `m` and its direct parameters not registered in modules.\"\n",
    "    children = list(m.children())\n",
    "    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()],[])\n",
    "    for p in m.parameters():\n",
    "        if id(p) not in children_p: children.append(ParameterModule(p))\n",
    "    return children\n",
    "\n",
    "flatten_model = lambda m: sum(map(flatten_model,children_and_parameters(m)),[]) if len(list(m.children())) else [m]\n",
    "\n",
    "# lr_range\n",
    "def lr_range(model, lr):\n",
    "    \"\"\"\n",
    "    Build differential learning rate from lr\n",
    "    Arguments:\n",
    "        lr :- float or slice\n",
    "        num_layer :- number of layers with requires_grad=True\n",
    "    Returns:\n",
    "        Depending upon lr\n",
    "    \"\"\"\n",
    "    if not isinstance(lr, slice): \n",
    "        return lr\n",
    "    \n",
    "    num_layer = [nn.Sequential(*flatten_model(model))]\n",
    "    if lr.start: \n",
    "        mult = lr.stop / lr.start\n",
    "        step = mult**(1/(num_layer-1))\n",
    "        res = np.array([lr.start*(step**i) for i in range(num_layer)])\n",
    "    else:\n",
    "        res = [lr.stop/10]*(num_layer-1) + [lr.stop]\n",
    "    \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealing_no(start, end, pct:float):\n",
    "    \"No annealing, always return `start`.\"\n",
    "    return start\n",
    "def annealing_linear(start, end, pct:float):\n",
    "    \"Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
    "    return start + pct * (end-start)\n",
    "def annealing_exp(start, end, pct:float):\n",
    "    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
    "    return start * (end/start) ** pct\n",
    "def annealing_cos(start, end, pct:float):\n",
    "    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
    "    cos_out = np.cos(np.pi * pct) + 1\n",
    "    return end + (start-end)/2 * cos_out\n",
    "def do_annealing_poly(start, end, pct:float, degree):\n",
    "    return end + (start-end) * (1-pct)**degree\n",
    "\n",
    "class Stepper():\n",
    "    \"Used to \\\"step\\\" from start, end ('vals') over 'n_iter' iterations on a schedule\"\n",
    "    def __init__(self, vals, n_iter:int, func=None):\n",
    "        self.start, self.end = (vals[0], vals[1]) if isinstance(vals, tuple) else (vals,0)\n",
    "        self.n_iter = max(1, n_iter)\n",
    "        if func is None:\n",
    "            self.func = annealing_linear if isinstance(vals, tuple) else annealing_no\n",
    "        else:\n",
    "            self.func = func\n",
    "        self.n = 0\n",
    "    \n",
    "    def step(self):\n",
    "        \"Return next value along annealed schedule\"\n",
    "        self.n += 1\n",
    "        return self.func(self.start, self.end, self.n/self.n_iter)\n",
    "        \n",
    "    @property\n",
    "    def is_done(self)->bool:\n",
    "        \"Return 'True' if schedule completed\"\n",
    "        return self.n >= self.n_iter\n",
    "\n",
    "class SmoothenValue():\n",
    "    \"Create a smooth moving average for a value (loss, etc) using `beta`.\"\n",
    "    def __init__(self, beta:float):\n",
    "        self.beta,self.n,self.mov_avg = beta,0,0\n",
    "    def add_value(self, val:float)->None:\n",
    "        \"Add `val` to calculate updated smoothed value.\"\n",
    "        self.n += 1\n",
    "        self.mov_avg = self.beta * self.mov_avg + (1 - self.beta) * val\n",
    "        self.smooth = self.mov_avg / (1 - self.beta ** self.n)\n",
    "    \n",
    "def LRFinder(model, \n",
    "             data, \n",
    "             loss_fn, \n",
    "             opt, \n",
    "             wd:int=0, \n",
    "             start_lr:float=1e-7, \n",
    "             end_lr:float=10, \n",
    "             num_it:int=100, \n",
    "             stop_div:bool=True,\n",
    "             smooth_beta:float=0.98):\n",
    "    model.train()\n",
    "    \n",
    "    stop = False\n",
    "    best_loss = 0.\n",
    "    flag = False\n",
    "    losses = []\n",
    "    iteration = 0\n",
    "    lrs = []\n",
    "    lrs.append(start_lr)\n",
    "    \n",
    "    start_lr = lr_range(model, start_lr)\n",
    "    start_lr = np.array(start_lr) if isinstance(start_lr, (tuple, list)) else start_lr\n",
    "    end_lr = lr_range(model, end_lr)\n",
    "    end_lr = np.array(end_lr) if isinstance(end_lr, (tuple, list)) else end_lr\n",
    "    \n",
    "    sched = Stepper((start_lr, end_lr), num_it, annealing_exp)\n",
    "    opt.lr = sched.start\n",
    "    smoothener = SmoothenValue(smooth_beta)\n",
    "    \n",
    "    # save model_dict\n",
    "    model_state = model.state_dict()\n",
    "    opt_state = opt.state_dict()\n",
    "\n",
    "    epochs = int(np.ceil(num_it/len(data)))\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for dat in data:\n",
    "            # Batch begin\n",
    "            inputs, labels = dat\n",
    "            opt.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "#             losses.append(loss.detach())\n",
    "            # On batch_begin\n",
    "            smoothener.add_value(loss.detach())\n",
    "            smooth_loss = smoothener.smooth\n",
    "            losses.append(smooth_loss)\n",
    "            loss.backward()\n",
    "            \n",
    "#             For adamW\n",
    "            for group in opt.param_groups:\n",
    "                for param in group['params']:\n",
    "                    param.data = param.data.add(-wd * group['lr'], param.data)\n",
    "                    \n",
    "            opt.step()\n",
    "            \n",
    "            # Change lr\n",
    "            new_lr = sched.step()\n",
    "            lrs.append(new_lr)\n",
    "            for i, param_group in enumerate(opt.param_groups):\n",
    "                param_group['lr'] = new_lr\n",
    "                \n",
    "            if iteration == 0 or smooth_loss < best_loss:\n",
    "                best_loss = smooth_loss\n",
    "            iteration += 1\n",
    "            \n",
    "            if sched.is_done or (stop_div and (smooth_loss > 4*best_loss or torch.isnan(loss))):\n",
    "                flag = True\n",
    "                break\n",
    "            \n",
    "            print('Iteration: ', iteration)\n",
    "            \n",
    "        if flag:\n",
    "            break\n",
    "    \n",
    "    # Load state back\n",
    "    model.load_state_dict(model_state)\n",
    "    opt.load_state_dict(opt_state)\n",
    "    \n",
    "    print('LR Finder is complete')\n",
    "    \n",
    "    lrs.pop()\n",
    "    return losses, lrs\n",
    "\n",
    "def plot_lr_finder(losses, \n",
    "                   lrs, \n",
    "                   skip_start:int=10, \n",
    "                   skip_end:int=5, \n",
    "                   suggestion:bool=False, \n",
    "                   return_fig:bool=None): \n",
    "#                    smoothen_by_spline:bool=True):\n",
    "    lrs = lrs[skip_start:-skip_end] if skip_end > 0 else lrs[skip_start:]\n",
    "    losses = losses[skip_start:-skip_end] if skip_end > 0 else losses[skip_start:]\n",
    "    losses = [x.item() for x in losses]\n",
    "#     if smoothen_by_spline:\n",
    "#         xs = np.arange(len(losses))\n",
    "#         spl = UnivariateSpline(xs, losses, k=1)\n",
    "#         losses = spl(xs)\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(lrs, losses)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Learning Rate\")\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "    \n",
    "    if suggestion:\n",
    "        try:\n",
    "            mg = (np.gradient(np.array(losses))).argmin()\n",
    "        except:\n",
    "            print(\"Failed to compute the gradients, there might not be enough points.\")\n",
    "            return\n",
    "        print(f\"Min numerical gradient: {lrs[mg]:.2E}\")\n",
    "        ax.plot(lrs[mg], losses[mg], markersize=10, marker='o', color='red')\n",
    "    \n",
    "    if return_fig is not None:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../Data/cifar10/train/'\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(path, transform=transform)\n",
    "\n",
    "data = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "Iteration:  60\n",
      "Iteration:  61\n",
      "Iteration:  62\n",
      "Iteration:  63\n",
      "Iteration:  64\n",
      "Iteration:  65\n",
      "Iteration:  66\n",
      "Iteration:  67\n",
      "Iteration:  68\n",
      "Iteration:  69\n",
      "Iteration:  70\n",
      "Iteration:  71\n",
      "Iteration:  72\n",
      "Iteration:  73\n",
      "Iteration:  74\n",
      "Iteration:  75\n",
      "Iteration:  76\n",
      "Iteration:  77\n",
      "Iteration:  78\n",
      "Iteration:  79\n",
      "Iteration:  80\n",
      "Iteration:  81\n",
      "Iteration:  82\n",
      "Iteration:  83\n",
      "Iteration:  84\n",
      "Iteration:  85\n",
      "Iteration:  86\n",
      "Iteration:  87\n",
      "Iteration:  88\n",
      "Iteration:  89\n",
      "Iteration:  90\n",
      "Iteration:  91\n",
      "Iteration:  92\n",
      "Iteration:  93\n",
      "Iteration:  94\n",
      "Iteration:  95\n",
      "Iteration:  96\n",
      "Iteration:  97\n",
      "Iteration:  98\n",
      "LR Finder is complete\n"
     ]
    }
   ],
   "source": [
    "losses, lrs = LRFinder(model, data, criterion, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 1.20E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_lr_finder(losses, lrs, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_one_cycle\n",
    "def fit_one_cycle(model,\n",
    "                  data,\n",
    "                  loss_fn,\n",
    "                  opt,\n",
    "                  cyc_len:int,\n",
    "                  tot_epochs:int,\n",
    "                  max_lr=0.001,\n",
    "                  moms=(0.95, 0.85),\n",
    "                  pct_start:float=0.3\n",
    "                  div_factor:float=25,\n",
    "                  final_div:float=None,\n",
    "                  wd:float=None,\n",
    "                  start_epoch:int=0):\n",
    "    \"\"\"\n",
    "    Fit model with one cycle policy\n",
    "    \"\"\"\n",
    "    max_lr = lr_range(model, max_lr)\n",
    "    if final_div is None: final_div = div_factor*qe4\n",
    "    if isinstance(max_lr, (tuple, list)): max_lr = np.array(max_lr)\n",
    "    \n",
    "    # train begin\n",
    "    # Initialize optimization params based on annealing schedule\n",
    "    res = {'epoch': start_epoch} if start_epoch is not None else None\n",
    "    n = len(data) * tot_epochs\n",
    "    a1 = int(n*pct_start)\n",
    "    a2 = n - a1\n",
    "    phases = ((a1, annealing_cos), (a2, annealing_cos))\n",
    "    low_lr = lr_max / div_factor\n",
    "    def steps(*steps_cfg):\n",
    "        return [Stepper(step, n_iter, func=func) for (step, (n_iter,func)) in zip(steps_cfg, phases)]\n",
    "    lr_scheds = steps((low_lr,lr_max), (lr_max, lr_max/final_div))\n",
    "    mom_scheds = steps(moms, (moms[1], moms[0]))\n",
    "    opt.lr = lr_scheds[0].start\n",
    "    opt.mom = mom_scheds[0].start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in optim.param_groups:\n",
    "    print(group)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_adam = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_adam.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_adam.mom = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_adam.mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
